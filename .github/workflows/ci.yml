# CI pipeline covering linting, type checking, testing, frontend checks,
# Docker image builds, and Playwright end-to-end coverage. Each job mirrors the
# specification outlined in the project backlog so regressions are caught early.
name: CI

on:
  # Validate all pull requests regardless of the source branch.
  pull_request:

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHONUNBUFFERED: "1"

jobs:
  lint:
    name: Lint (ruff / formatting)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-3.12-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Ruff lint
        run: ruff check .
      - name: Check formatting
        run: |
          black --check src tests
          isort --check-only src tests

  typecheck:
    name: Typecheck (mypy)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: lint
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-3.12-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run mypy
        run: mypy src

  tests:
    name: Tests (pytest)
    runs-on: ubuntu-latest
    timeout-minutes: 25
    needs: typecheck
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.11", "3.12"]
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-${{ matrix.python-version }}-
            pip-${{ runner.os }}-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run pytest
        run: |
          mkdir -p reports
          pytest --junitxml=reports/pytest-junit.xml --cov=src --cov-report=xml
      - name: Upload coverage and junit
        uses: actions/upload-artifact@v4
        with:
          name: pytest-${{ matrix.python-version }}
          path: |
            coverage.xml
            reports/pytest-junit.xml
      - name: Verify MCP registration
        if: matrix.python-version == '3.12'
        run: |
          python - <<'PY'
          """Ensure all documented MCP tools are registered."""
          import importlib

          module = importlib.import_module("chart_mcp.mcp_main")

          class DummyServer:
              def __init__(self) -> None:
                  self.names: list[str] = []

              def tool(self, name: str):
                  def decorator(func):
                      self.names.append(name)
                      return func

                  return decorator

          server = DummyServer()
          module.register(server)
          expected = set(module.REGISTERED_TOOL_NAMES)
          missing = sorted(expected - set(server.names))
          if missing:
              raise SystemExit(f"Missing MCP tools: {', '.join(missing)}")
          PY

  build-backend:
    name: Build backend image
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: tests
    env:
      REGISTRY_URL: ${{ secrets.REGISTRY_URL }}
      REGISTRY_USERNAME: ${{ secrets.REGISTRY_USERNAME }}
      REGISTRY_PASSWORD: ${{ secrets.REGISTRY_PASSWORD }}
      REGISTRY_IMAGE_NAME: ${{ secrets.IMAGE_NAME }}
    steps:
      - uses: actions/checkout@v4
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Cache Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: buildx-${{ runner.os }}-${{ github.sha }}
          restore-keys: |
            buildx-${{ runner.os }}-
      - name: Prepare image metadata
        id: image-meta
        run: |
          echo "local-tag=chart-mcp:${GITHUB_SHA}" >> "$GITHUB_OUTPUT"
          if [ -n "${REGISTRY_URL}" ] && [ -n "${REGISTRY_IMAGE_NAME}" ] && [ -n "${REGISTRY_USERNAME}" ] && [ -n "${REGISTRY_PASSWORD}" ]; then
            echo "should-push=true" >> "$GITHUB_OUTPUT"
            echo "registry-tag=${REGISTRY_URL}/${REGISTRY_IMAGE_NAME}:${GITHUB_SHA}" >> "$GITHUB_OUTPUT"
          else
            echo "should-push=false" >> "$GITHUB_OUTPUT"
          fi
      - name: Log in to registry
        if: ${{ steps.image-meta.outputs.should-push == 'true' }}
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY_URL }}
          username: ${{ env.REGISTRY_USERNAME }}
          password: ${{ env.REGISTRY_PASSWORD }}
      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile
          push: false
          load: true
          tags: ${{ steps.image-meta.outputs.local-tag }}
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max
      - name: Move Docker cache
        run: |
          if [ -d /tmp/.buildx-cache-new ]; then
            rm -rf /tmp/.buildx-cache
            mv /tmp/.buildx-cache-new /tmp/.buildx-cache
          fi
      - name: Push image to registry
        if: ${{ steps.image-meta.outputs.should-push == 'true' }}
        env:
          LOCAL_TAG: ${{ steps.image-meta.outputs.local-tag }}
          REGISTRY_TAG: ${{ steps.image-meta.outputs.registry-tag }}
        run: |
          docker tag "$LOCAL_TAG" "$REGISTRY_TAG"
          docker push "$REGISTRY_TAG"
      - name: Run container healthcheck
        env:
          API_TOKEN: testingtoken
          ALLOWED_ORIGINS: http://localhost:3000
        run: |
          docker run -d --rm -p 8000:8000 \
            -e API_TOKEN="$API_TOKEN" \
            -e ALLOWED_ORIGINS="$ALLOWED_ORIGINS" \
            -e PLAYWRIGHT=1 \
            --name chart-mcp-ci \
            ${{ steps.image-meta.outputs.local-tag }}
          trap 'docker stop chart-mcp-ci' EXIT
          python docker/healthcheck.py

  build-frontend:
    name: Frontend build & unit tests
    runs-on: ubuntu-latest
    timeout-minutes: 25
    needs: tests
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v3
        with:
          version: 9.12.1
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "pnpm"
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Typecheck frontend
        run: pnpm --filter ai-chatbot exec tsc --noEmit
      - name: Run Vitest
        run: |
          mkdir -p reports
          pnpm --filter ai-chatbot exec vitest run --coverage --reporter=junit --outputFile=reports/vitest-junit.xml
      - name: Upload Vitest artifacts
        uses: actions/upload-artifact@v4
        with:
          name: vitest-results
          path: |
            coverage
            reports/vitest-junit.xml

  playwright-e2e:
    name: Playwright e2e
    runs-on: ubuntu-latest
    timeout-minutes: 40
    needs: build-frontend
    env:
      MCP_API_BASE: http://127.0.0.1:8000
      MCP_API_TOKEN: ${{ secrets.MCP_API_TOKEN || 'playwright-token' }}
      MCP_SESSION_USER: regular
      PLAYWRIGHT: "1"
      PLAYWRIGHT_TEST_BASE_URL: http://127.0.0.1:3000
      PLAYWRIGHT_USE_REAL_SERVICES: "1"
      AUTH_SECRET: ${{ secrets.AUTH_SECRET }}
      POSTGRES_URL: ${{ secrets.POSTGRES_URL }}
      BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
      REDIS_URL: ${{ secrets.REDIS_URL }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      LLM_PROVIDER: openai
      LLM_MODEL: gpt-5-nano
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v3
        with:
          version: 9.12.1
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "pnpm"
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Install Playwright browsers
        run: pnpm --filter ai-chatbot exec playwright install --with-deps
      - name: Launch Postgres for Playwright (fallback)
        if: env.POSTGRES_URL == ''
        env:
          POSTGRES_DB: playwright
          POSTGRES_PASSWORD: playwright
          POSTGRES_USER: playwright
        run: |
          docker run -d --rm --name playwright-postgres \
            -e POSTGRES_DB="$POSTGRES_DB" \
            -e POSTGRES_PASSWORD="$POSTGRES_PASSWORD" \
            -e POSTGRES_USER="$POSTGRES_USER" \
            -p 5432:5432 \
            postgres:15-alpine
          echo "PLAYWRIGHT_POSTGRES_CONTAINER=playwright-postgres" >> "$GITHUB_ENV"
      - name: Wait for Postgres
        if: env.POSTGRES_URL == ''
        env:
          POSTGRES_USER: playwright
        run: |
          ATTEMPTS=60
          for attempt in $(seq 1 "$ATTEMPTS"); do
            if docker exec playwright-postgres pg_isready -U "$POSTGRES_USER" >/dev/null 2>&1; then
              echo "Postgres became ready after $attempt attempt(s)."
              break
            fi
            sleep 2
          done
          if ! docker exec playwright-postgres pg_isready -U "$POSTGRES_USER" >/dev/null 2>&1; then
            echo "Postgres failed to become ready." >&2
            docker logs playwright-postgres >&2 || true
            exit 1
          fi
      - name: Export Playwright database URL
        run: |
          if [ -z "${POSTGRES_URL:-}" ]; then
            echo "POSTGRES_URL=postgresql://playwright:playwright@127.0.0.1:5432/playwright" >> "$GITHUB_ENV"
          else
            echo "Using POSTGRES_URL provided via secrets"
            echo "POSTGRES_URL=$POSTGRES_URL" >> "$GITHUB_ENV"
          fi
      - name: Run database migrations
        working-directory: frontend/ai-chatbot
        env:
          POSTGRES_URL: ${{ env.POSTGRES_URL }}
        run: pnpm exec drizzle-kit push
      - name: Launch API and SearxNG containers
        env:
          API_TOKEN: ${{ secrets.MCP_API_TOKEN || 'playwright-token' }}
          ALLOWED_ORIGINS: http://127.0.0.1:3000,http://localhost:3000
          SEARXNG_BASE_URL: http://127.0.0.1:8080
        run: |
          docker compose -f docker/docker-compose.yml up -d api searxng
      - name: Wait for backend healthcheck
        run: |
          ATTEMPTS=60
          for attempt in $(seq 1 "$ATTEMPTS"); do
            if curl -fsS http://127.0.0.1:8000/health >/dev/null; then
              echo "Backend became healthy after $attempt attempt(s)."
              exit 0
            fi
            sleep 2
          done
          echo "Backend failed to become healthy." >&2
          docker compose -f docker/docker-compose.yml logs api >&2 || true
          exit 1
      - name: Start Next.js server
        working-directory: frontend/ai-chatbot
        env:
          PORT: 3000
          AUTH_SECRET: ${{ env.AUTH_SECRET || 'playwright-secret' }}
          MCP_API_BASE: http://127.0.0.1:8000
          MCP_SESSION_USER: regular
          MCP_API_TOKEN: ${{ secrets.MCP_API_TOKEN || 'playwright-token' }}
          NEXT_PUBLIC_API_BASE_URL: http://127.0.0.1:8000
          NEXT_PUBLIC_ENABLE_E2E_STREAM_DEBUG: "1"
          POSTGRES_URL: ${{ env.POSTGRES_URL }}
          BLOB_READ_WRITE_TOKEN: ${{ env.BLOB_READ_WRITE_TOKEN }}
          REDIS_URL: ${{ env.REDIS_URL }}
          OPENAI_API_KEY: ${{ env.OPENAI_API_KEY }}
          PLAYWRIGHT_USE_REAL_SERVICES: "1"
          LLM_PROVIDER: ${{ env.LLM_PROVIDER }}
          LLM_MODEL: ${{ env.LLM_MODEL }}
        run: |
          LOG_FILE="$GITHUB_WORKSPACE/frontend/ai-chatbot/.next-dev.log"
          : > "$LOG_FILE"
          pnpm run dev:playwright > "$LOG_FILE" 2>&1 &
          NEXT_PID=$!
          sleep 5
          if ! kill -0 "$NEXT_PID" 2>/dev/null; then
            echo "Next.js dev server exited before becoming ready." >&2
            cat "$LOG_FILE" >&2 || true
            exit 1
          fi
          echo "NEXT_PID=$NEXT_PID" >> "$GITHUB_ENV"
          echo "NEXT_LOG=$LOG_FILE" >> "$GITHUB_ENV"
      # Aggregate stdout/stderr and the server log into a dedicated folder so we
      # can publish them as downloadable artifacts after the run.
      - name: Prepare Playwright log directory
        run: |
          mkdir -p playwright-logs
      - name: Wait for frontend availability
        working-directory: frontend/ai-chatbot
        run: |
          ATTEMPTS=120
          for attempt in $(seq 1 "$ATTEMPTS"); do
            if curl -fsS http://127.0.0.1:3000 >/dev/null; then
              echo "Frontend became available after $attempt attempt(s)."
              exit 0
            fi
            if ! kill -0 "${NEXT_PID:-}" 2>/dev/null; then
              echo "Next.js process exited while waiting for readiness." >&2
              if [ -n "${NEXT_LOG:-}" ] && [ -f "$NEXT_LOG" ]; then
                echo "----- Next.js log -----" >&2
                cat "$NEXT_LOG" >&2
                echo "-----------------------" >&2
              fi
              exit 1
            fi
            sleep 1
          done
          echo "Frontend failed to become available within the timeout." >&2
          if [ -n "${NEXT_LOG:-}" ] && [ -f "$NEXT_LOG" ]; then
            echo "----- Next.js log -----" >&2
            cat "$NEXT_LOG" >&2
            echo "-----------------------" >&2
          fi
          exit 1
      # Stream the Playwright reporter output to both stdout (for live logs) and
      # a file that we can bundle into the artifact archive without losing the
      # original exit code when the suite fails.
      - name: Run Playwright tests
        env:
          PLAYWRIGHT_BASE_URL: http://127.0.0.1:3000
          PLAYWRIGHT_SKIP_WEB_SERVER: "1"
          OPENAI_API_KEY: ${{ env.OPENAI_API_KEY }}
          POSTGRES_URL: ${{ env.POSTGRES_URL }}
          REDIS_URL: ${{ env.REDIS_URL }}
          BLOB_READ_WRITE_TOKEN: ${{ env.BLOB_READ_WRITE_TOKEN }}
          PLAYWRIGHT_USE_REAL_SERVICES: "1"
        run: |
          set -o pipefail
          pnpm --filter ai-chatbot exec playwright test --reporter=line \
            | tee "$GITHUB_WORKSPACE/playwright-logs/playwright-run.log"
      - name: Stop Next.js server
        if: always()
        run: |
          if [ -n "${NEXT_PID:-}" ]; then
            kill "$NEXT_PID" || true
          fi
      # Gather the various logs (Next.js dev output, Playwright test-results,
      # HTML report) into the aggregation folder so downstream jobs only need to
      # download a single artifact to inspect failures.
      - name: Collect Playwright logs
        if: always()
        run: |
          mkdir -p playwright-logs
          if [ -n "${NEXT_LOG:-}" ] && [ -f "$NEXT_LOG" ]; then
            cp "$NEXT_LOG" playwright-logs/next-dev.log
          fi
          if [ -d frontend/ai-chatbot/test-results ]; then
            rm -rf playwright-logs/test-results
            cp -R frontend/ai-chatbot/test-results playwright-logs/test-results
          fi
          if [ -d playwright-report ]; then
            cp -R playwright-report playwright-logs/report-html
          fi
      - name: Shutdown containers
        if: always()
        run: |
          docker compose -f docker/docker-compose.yml down
          if [ -n "${PLAYWRIGHT_POSTGRES_CONTAINER:-}" ]; then
            docker stop "$PLAYWRIGHT_POSTGRES_CONTAINER" || true
          fi
      - name: Upload Playwright logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-logs
          path: playwright-logs
      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: playwright-report
