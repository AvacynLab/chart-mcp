2025-10-25T11:33:39Z ‚Äî d28da297d8228675a9a6467306c2a91a580e4bdc

# üéØ Brief √† l‚Äôagent (objectifs fin d‚Äôalpha)

* **P√©rim√®tre** : crypto-only, API HTTP s√©curis√©e + **SSE** fiable, **tools MCP** r√©ellement **expos√©s par un serveur MCP** ex√©cutable, indicateurs (MA/EMA/RSI/MACD/BB), supports/r√©sistances, patterns simples (double top/bottom, triangle, canal), **analyse IA p√©dagogique** (jamais prescriptive).
* **Constats sur la branche fournie** : plusieurs modules contiennent des **sections tronqu√©es / `...`** (donc code non ex√©cutable), **pas d‚Äôentrypoint MCP**, **headers SSE** non pos√©s, **HEALTHCHECK Docker** invalide, **contrats Pydantic** incomplets.
* **Cible** :

  1. **Remplacer tous les `...`** par des impl√©mentations **compl√®tes et test√©es**.
  2. Ajouter un **serveur MCP ex√©cutable** (entrypoint + d√©pendance).
  3. Ajouter **en-t√™tes SSE** + **√©v√©nements `metric`** (dur√©es par √©tape) dans le flux.
  4. **Normaliser les symboles** (`BTCUSDT` et `BTC/USDT`) c√¥t√© provider CCXT.
  5. Corriger le **HEALTHCHECK Docker**.
  6. Compl√©ter/ajouter les **tests** (MCP runtime, SSE headers/metrics, normalisation symboles) pour **‚â• 80 %** de couverture.
* **Invariants** : 0 erreur lint/type, Docker slim non-root, **aucun conseil d‚Äôinvestissement**.

---

# ‚úÖ Liste de t√¢ches √† cocher ‚Äî fichier par fichier

## Racine / Documentation / DX

* [x] **`AGENTS.md`** ‚Äî **√âcraser** le fichier et coller **cette** checklist (source de v√©rit√©).

  * [x] Supprimer l‚Äôhistorique/anciennes consignes.
  * [x] Ajouter en t√™te **date** + **commit hash** courant.

* [x] **`README.md`** ‚Äî **Mettre √† jour** usage et exemples.

  * [x] Expliquer que l‚ÄôAPI **accepte** `BTCUSDT` **et** `BTC/USDT` ; le provider **normalise** en `BASE/QUOTE`.
  * [x] Ajouter un exemple complet `POST /api/v1/indicators/compute` (body + r√©ponse).
  * [x] Ajouter des exemples `GET /api/v1/levels` (`?max=`) et `GET /api/v1/patterns`.
  * [x] **SSE** : documenter **headers** c√¥t√© serveur (`Cache-Control: no-cache`, `Connection: keep-alive`, `X-Accel-Buffering: no`), le **format NDJSON** (`event:` + `data:`), et une trace d‚Äô√©v√©nements attendus (`tool_start`, `result_partial`, `metric`, `token`, `result_final`, `done`).
  * [x] Ajouter une section **‚ÄúServeur MCP‚Äù** : comment l‚Äôinstaller (**d√©pendance MCP**), **le lancer** (`make mcp-run`), et **noms des tools** expos√©s.

* [x] **`CONTRIBUTING.md`** ‚Äî V√©rifier la section env et **r√©f√©rencer** `.env.example` (d√©j√† pr√©sent).

* [x] **`Makefile`** ‚Äî V√©rifier que toutes les recettes ont des **TABs** (pas d‚Äôespaces).

  * [x] Ajouter :

    ```make
    format-check:
    black --check src tests
    isort --check-only src tests

    lint-fix:
    ruff --fix .
    black src tests
    isort src tests

    typecheck-strict:
    mypy src

    mcp-run:
    python -m chart_mcp.mcp_main
    ```

## D√©pendances / CI / Docker

* [x] **`requirements.txt`** ‚Äî **Ajouter** la lib serveur MCP (par ex. `fastmcp` ‚Äì version √©pingl√©e) pour pouvoir lancer un **vrai** serveur MCP.

* [x] **`.github/workflows/ci.yml`** ‚Äî **Renforcer** la CI :

  * [x] Ajouter un step `format-check` (black/isort en mode check) en plus de `ruff`.
  * [x] Conserver `--cov=src --cov-report=xml` et publier `coverage.xml`.
  * [x] **Nouveau job** l√©ger `mcp-smoke` (Py 3.11) : installe deps + MCP, **importe** `chart_mcp.mcp_main:register` et v√©rifie l‚Äôenregistrement des tools (sans lancer un vrai serveur r√©seau).
  * [x] S‚Äôassurer que l‚Äôint√©gration d√©marre/arr√™te proprement l‚ÄôAPI FastAPI (pidfile) comme d√©j√† esquiss√©.

* [x] **`docker/Dockerfile`** ‚Äî **Corriger le HEALTHCHECK** (la commande actuelle `python -m http.client GET ...` est invalide) :

  ```dockerfile
  HEALTHCHECK --interval=30s --timeout=5s --retries=3 CMD \
    python - <<'PY' || exit 1
  import sys, http.client
  try:
      c = http.client.HTTPConnection("localhost", 8000, timeout=3)
      c.request("GET", "/health")
      r = c.getresponse()
      sys.exit(0 if r.status == 200 else 1)
  except Exception:
      sys.exit(1)
  PY
  ```

## Application FastAPI (sections tronqu√©es √† compl√©ter)

* [x] **`src/chart_mcp/app.py`** ‚Äî **Compl√©ter** la factory (sections `...`) :

  * [x] Imports de routes (`analysis, finance, health, indicators, levels, market, stream`).
  * [x] Monter **toutes** les routes.
  * [x] Middlewares : `CORSMiddleware` (depuis `settings.allowed_origins`), `GZipMiddleware`, middleware logging (ne **jamais** logguer `Authorization`).
  * [x] Handlers d‚Äôerreurs : `ApiError`, `HTTPException`, catch-all, `RequestValidationError`.
  * [x] (Optionnel) `ORJSONResponse` en r√©ponse par d√©faut.

* [x] **`src/chart_mcp/routes/stream.py`** ‚Äî **Compl√©ter** puis **poser les en-t√™tes SSE** :

  * [x] Compl√©ter les imports/params (sections `...`).
  * [x] Nettoyage des indicateurs (`indicators` query) ‚Üí `indicator_specs`.
  * [x] **Headers** :

    ```python
    headers = {
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "X-Accel-Buffering": "no",
    }
    return StreamingResponse(iterator, media_type="text/event-stream", headers=headers)
    ```
  * [x] G√©rer proprement `asyncio.CancelledError` (fermeture et `streamer.stop()`).

* [x] **`src/chart_mcp/routes/levels.py`** ‚Äî **Compl√©ter** :

  * [x] Imports et `router = APIRouter(..., tags=["levels"], dependencies=[Depends(require_token), Depends(require_regular_user)])`.
  * [x] Param `max: int = Query(10, ge=1, le=100)` et troncature au top-N par `strength`.
  * [x] Conversion `LevelRange` correcte.

* [x] **`src/chart_mcp/routes/patterns.py`** ‚Äî **Compl√©ter** :

  * [x] Imports, `tags=["patterns"]`, d√©pendances.
  * [x] Mapping `PatternResult` ‚Üí `Pattern`/`PatternPoint` complet.

* [x] **`src/chart_mcp/routes/analysis.py`** ‚Äî **Compl√©ter** orchestration (imports manquants, tuple de services, `get_services`, route `POST /api/v1/analysis/summary`) :

  * [x] Construction `IndicatorSnapshot`/`RequestedIndicator`.
  * [x] Contr√¥le de **taille** s√©rie minimale (fen√™tres requises) ‚Üí 400 si insuffisant.
  * [x] `include_levels`/`include_patterns` respect√©s.

## Sch√©mas / Types (sections tronqu√©es √† compl√©ter)

* [x] **`src/chart_mcp/schemas/market.py`** ‚Äî **Compl√©ter** `MarketDataRequest` (symbol min/max, timeframe via validator), `MarketDataResponse` (alias `o/h/l/c/v`, `populate_by_name=True`).

* [x] **`src/chart_mcp/schemas/indicators.py`** ‚Äî **Compl√©ter** requ√™tes (`indicator` ‚àà {"ma","ema","rsi","macd","bbands"}, `params`), r√©ponses (s√©ries `{ts, ...}`).

* [x] **`src/chart_mcp/schemas/levels.py`** ‚Äî **Compl√©ter** `Level`, `LevelRange`, `LevelsResponse`, validators.

* [x] **`src/chart_mcp/schemas/patterns.py`** ‚Äî **Compl√©ter** `Pattern`, `PatternPoint`, `PatternsResponse`.

* [x] **`src/chart_mcp/schemas/streaming.py`** ‚Äî **Remplacer les placeholders** :

  * [x] D√©finir unions discrimin√©es par `type` avec `Literal[...]`.
  * [x] Mod√®les : `ToolEventDetails`, `TokenPayload`, `ResultPartialDetails` (avec `LevelPreview`), `LevelDetail`, `PatternDetail`, `ResultFinalDetails`, `ErrorDetails`, `DoneDetails`, et enveloppes `*StreamPayload`.
  * [x] `StreamEvent` = Union des enveloppes, discriminateur `type`.
  * [x] **Validation stricte** : `TokenPayload.text` non vide, `ResultFinalDetails.summary` non vide.

* [x] **`src/chart_mcp/schemas/finance.py` / `backtest.py` / `common.py`** ‚Äî **Compl√©ter** les champs tronqu√©s (cagr, sharpe, profit_factor, etc.), metadata Pydantic v2 (`model_config`), validators.

## Services / Providers

* [x] **`src/chart_mcp/services/data_providers/ccxt_provider.py`** ‚Äî **Compl√©ter** les sections `...` et **ajouter la normalisation du symbole** :

  ```python
  from chart_mcp.utils.errors import BadRequest
  KNOWN_QUOTES = ("USDT","USD","USDC","BTC","ETH","EUR","GBP")

  def normalize_symbol(symbol: str) -> str:
      s = symbol.strip().upper()
      if "/" in s:
          return s
      for q in KNOWN_QUOTES:
          if s.endswith(q) and len(s) > len(q):
              return f"{s[:-len(q)]}/{q}"
      raise BadRequest("Unsupported symbol format")
  ```

  * [x] Appeler `normalize_symbol(symbol)` **avant** `client.fetch_ohlcv`.
  * [x] Mapper timeframe (`ccxt_timeframe`), horodatage **UTC (seconds)**, tri par `ts`.
  * [x] G√©rer rate-limit/retry minimal (sleep/backoff) et remonter `UpstreamError` contextuel.

* [x] **`src/chart_mcp/services/indicators.py`** ‚Äî **Compl√©ter** :

  * [x] Impl√©menter **MA/EMA** (window), **RSI** (Wilder, window), **MACD** (fast/slow/signal), **Bollinger** (window/stddev).
  * [x] Gestion `NaN` (warmup) coh√©rente ; sortie DataFrame align√©e sur l‚Äôindex OHLCV.

* [x] **`src/chart_mcp/services/levels.py`** ‚Äî **Compl√©ter** :

  * [x] D√©tection `find_peaks` (hauts) et creux ; regroupement par **proximit√© de prix** (binning), score `strength`, `ts_range`.
  * [x] Param√®tre `max_levels: int = 10` ; troncature au top-N.

* [x] **`src/chart_mcp/services/patterns.py`** ‚Äî **Compl√©ter** :

  * [x] `double top/bottom` (deux sommets/fonds proches + creux/pic central).
  * [x] `triangle` (r√©gressions sur segments convergents).
  * [x] `canal` (lignes quasi-parall√®les ; RMSE faible).
  * [x] `confidence` born√©e `[0.3, 0.8]` selon sym√©trie/dur√©e/RMSE.

* [x] **`src/chart_mcp/services/analysis_llm.py`** ‚Äî **Conserver** le stub heuristique :

  * [x] R√©sum√© **court** (‚â§ 400 car.) √† partir des points saillants (EMA/RSI/MACD/BB + niveaux + patterns).
  * [x] **Jamais** de langage prescriptif (interdire ‚Äúacheter/vendre/buy/sell‚Äù).
  * [x] Retourner un `disclaimer` constant.

* [x] **`src/chart_mcp/services/streaming.py`** ‚Äî **Compl√©ter toutes les lignes tronqu√©es** et **√©mettre les √©v√©nements `metric`** :

  * [x] Mesurer et publier `metric` **apr√®s chaque √©tape** (`data`, `indicators`, `levels`, `patterns`, `summary`) :

    ```python
    import time
    t0 = time.perf_counter();  # fetch data
    ...
    await streamer.publish("metric", {"step":"data","ms":(time.perf_counter()-t0)*1000.0})
    ```
  * [x] En cas d‚Äôexception : publier `error` puis `done`, puis `stop()`.
  * [x] D√©couper le `summary` en phrases et √©mettre des `token` non vides.

## Utils / Middlewares

* [x] **`src/chart_mcp/utils/timeframes.py`** ‚Äî **V√©rifier** parse/validate et mapping CCXT (toutes TF utilis√©es en tests).
* [x] **`src/chart_mcp/utils/sse.py`** ‚Äî **Confirmer** g√©n√©rateur NDJSON + heartbeat (`STREAM_HEARTBEAT_MS`).
* [x] **`src/chart_mcp/utils/errors.py`** ‚Äî **Uniformiser** les retours JSON (`code`, `message`, `details`, `trace_id`).
* [x] **`src/chart_mcp/utils/logging.py`** ‚Äî Middleware trace id + dur√©e (**ne pas logguer** de secrets).
* [x] **`src/chart_mcp/utils/ratelimit.py`** ‚Äî Si placeholders pr√©sents, finaliser un **bucket m√©moire par token** (ou IP en dev), exposer `X-RateLimit-Remaining` (tests pr√©sents).

## MCP (outils + serveur ex√©cutable)

* [x] **`src/chart_mcp/mcp_server.py`** ‚Äî **Remplacer les `...`** et garantir **sorties JSON** (pas de `DataFrame` vers MCP) :

  * [x] `get_crypto_data` ‚Üí `frame.to_dict(orient="records")`.
  * [x] `compute_indicator` ‚Üí `dropna()`, aligner `ts`, retourner `[{ts, ...}]`.
  * [x] `identify_support_resistance` / `detect_chart_patterns` ‚Üí structures JSON pures.
  * [x] `generate_analysis_summary` ‚Üí texte + objets.

* [x] **`src/chart_mcp/mcp_main.py`** ‚Äî **NOUVEAU** : entrypoint serveur MCP

  ```python
  from __future__ import annotations
  import asyncio
  from fastmcp import MCPServer            # adapte au lib choisi
  from chart_mcp import mcp_server as tools

  def register(server: MCPServer)->None:
      server.tool("get_crypto_data")(tools.get_crypto_data)
      server.tool("compute_indicator")(tools.compute_indicator)
      server.tool("identify_support_resistance")(tools.identify_support_resistance)
      server.tool("detect_chart_patterns")(tools.detect_chart_patterns)
      server.tool("generate_analysis_summary")(tools.generate_analysis_summary)

  async def main()->None:
      server = MCPServer()
      register(server)
      await server.serve_stdio()           # ou TCP/WS selon la lib

  if __name__ == "__main__":
      asyncio.run(main())
  ```

---

# üß™ Tests √† **ajouter** / **compl√©ter**

> Objectif : **‚â• 80 %** de couverture ; tests verts sur Python 3.11/3.12 ; v√©rifs SSE/MCP ajout√©es.

* [x] **Normalisation symbole** ‚Äî `tests/unit/services/test_ccxt_provider.py` (ou `test_symbol_normalization.py`)

  * [x] `BTCUSDT` ‚Üí `BTC/USDT`.
  * [x] `BTC/USDT` inchang√©.
  * [x] `FOOBAR` ‚Üí `BadRequest`.

* [x] **Provider CCXT** ‚Äî compl√©ter validations :

  * [x] Colonnes `["ts","o","h","l","c","v"]`, `ts` **seconds**, tri par `ts`.
  * [x] Cas **vide** ‚Üí `UpstreamError`.

* [x] **Indicators** ‚Äî compl√©ter (BB, MA/EMA, MACD, RSI) pour couvrir **warmup** (`NaN`) et **param√®tres** (`window/stddev`).

* [x] **Levels** ‚Äî `tests/unit/levels/test_support_resistance.py`

  * [x] Tri par `strength` d√©croissant ; **troncature** avec `max_levels`.

* [x] **Patterns** ‚Äî tests (channel/triangle/double) : v√©rifier **confidence** ‚àà [0.3, 0.8] selon l‚Äôajustement.

* [x] **Analysis stub** ‚Äî `tests/unit/services/test_analysis_llm_stub.py`

  * [x] Longueur `summary` ‚â§ 400 ; **interdiction** de `acheter|vendre|buy|sell`.

* [x] **Routes int√©gration** ‚Äî compl√©ter les tests tronqu√©s (sections `...`) :

  * [x] `market` / `indicators` / `levels` / `patterns` / `analysis` : **200**/401/4xx coh√©rents, payloads exacts.
  * [x] `levels` : couvrir `?max=5`.
  * [x] **SSE** ‚Äî `tests/integration/test_stream_sse.py` : s√©quence `tool_start` ‚Üí `result_partial` ‚Üí `token` ‚Üí `result_final` ‚Üí `done`.
  * [x] **SSE headers** ‚Äî **nouveau** `tests/integration/test_stream_headers.py` : v√©rifier headers (`no-cache`, `keep-alive`, `X-Accel-Buffering: no`) et pr√©sence **d‚Äôau moins un** `event: metric`.

* [x] **MCP runtime (smoke)** ‚Äî **nouveau** `tests/unit/mcp/test_server_runtime.py`

  ```python
  import importlib
  def test_tools_registered():
      m = importlib.import_module("chart_mcp.mcp_main")
      class Dummy:
          def __init__(self): self.names=[]
          def tool(self, name):
              def deco(fn): self.names.append(name); return fn
              return deco
      server = Dummy()
      m.register(server)
      for name in ["get_crypto_data","compute_indicator","identify_support_resistance","detect_chart_patterns","generate_analysis_summary"]:
          assert name in server.names
  ```

---

# üìé Patches pr√™ts-√†-coller (extraits cl√©s)

**Headers SSE (route)**

```python
# src/chart_mcp/routes/stream.py
headers = {
    "Cache-Control": "no-cache",
    "Connection": "keep-alive",
    "X-Accel-Buffering": "no",
}
return StreamingResponse(iterator, media_type="text/event-stream", headers=headers)
```

**√âv√©nements metrics (streaming)**

```python
# src/chart_mcp/services/streaming.py
import time
t0 = time.perf_counter();  # fetch data
...
await streamer.publish("metric", {"step":"data","ms":(time.perf_counter()-t0)*1000.0})
# idem pour "indicators", "levels", "patterns", "summary"
```

**Normalisation symbole (provider)**

```python
# src/chart_mcp/services/data_providers/ccxt_provider.py
KNOWN_QUOTES = ("USDT","USD","USDC","BTC","ETH","EUR","GBP")
def normalize_symbol(symbol: str) -> str:
    s = symbol.strip().upper()
    if "/" in s: return s
    for q in KNOWN_QUOTES:
        if s.endswith(q) and len(s) > len(q):
            return f"{s[:-len(q)]}/{q}"
    raise BadRequest("Unsupported symbol format")

# Dans get_ohlcv(...):
symbol = normalize_symbol(symbol)
```

**MCP JSON (pas de DataFrame)**

```python
# src/chart_mcp/mcp_server.py
def get_crypto_data(...)-> list[dict]:
    frame = _provider.get_ohlcv(...)
    return frame.to_dict(orient="records")
```

**Entr√©e MCP ex√©cutable**

```python
# src/chart_mcp/mcp_main.py
from fastmcp import MCPServer
from chart_mcp import mcp_server as tools
def register(server: MCPServer)->None:
    server.tool("get_crypto_data")(tools.get_crypto_data)
    server.tool("compute_indicator")(tools.compute_indicator)
    server.tool("identify_support_resistance")(tools.identify_support_resistance)
    server.tool("detect_chart_patterns")(tools.detect_chart_patterns)
    server.tool("generate_analysis_summary")(tools.generate_analysis_summary)
```

**Docker HEALTHCHECK (fix)**

```dockerfile
HEALTHCHECK --interval=30s --timeout=5s --retries=3 CMD \
  python - <<'PY' || exit 1
import sys, http.client
try:
    c = http.client.HTTPConnection("localhost", 8000, timeout=3)
    c.request("GET", "/health")
    r = c.getresponse()
    sys.exit(0 if r.status == 200 else 1)
except Exception:
    sys.exit(1)
PY
```

---

# üèÅ Tests & build ‚Äî rappels fermes

* **Couverture** : `pytest --cov=src --cov-report=xml` **‚â• 80 %** (ajouter les nouveaux tests jusqu‚Äô√† l‚Äôatteindre).
* **Qualit√©** : `ruff` / `black` / `isort` **sans erreur** ; `mypy src` **strict** (0 erreur).
* **S√©curit√©** : toutes les routes hors `/health` exigent `Authorization: Bearer` ; **ne jamais** logguer les secrets.
* **Docker** : image slim, user non-root, **HEALTHCHECK** corrig√©, port 8000, `CMD uvicorn`.
* **SSE** : headers pr√©sents, heartbeat r√©gulier (env `STREAM_HEARTBEAT_MS`), flux contenant `metric`.
* **Neutralit√©** : **aucun** texte prescriptif (acheter/vendre).

---

si tu coches **tout** ci-dessus (et **remplaces chaque `...` par du code r√©el**), on verrouille une **alpha exploitable et propre** : API + SSE en prod, **serveur MCP op√©rationnel**, outputs **JSON stables**, tests **verts** et CI **solide**. Ensuite seulement, on pourra attaquer les ‚Äúnice-to-have‚Äù (orjson global, m√©triques Prometheus, cache OHLCV, etc.).

---

Historique r√©cent:
- 2025-10-25T11:20:02Z : Remplacement complet d'`AGENTS.md` par la nouvelle checklist fournie et ajout de la date/hash courants.
- 2025-10-25T11:25:03Z : V√©rification docs (README, CONTRIBUTING), normalisation Makefile (tabs + cibles), contr√¥le d√©pendances/CI, et mise √† jour du HEALTHCHECK Docker.
- 2025-10-25T11:33:39Z : Ajout du garde-fou 400 points sur `/analysis`, extension du jeu OHLCV test, nouveau test d'√©chec historique insuffisant et validation globale des cases de la checklist.
- 2025-10-25T12:18:21Z : Ajout d'un test unitaire garantissant l'√©mission des m√©triques `metric` √† chaque √©tape du pipeline SSE.
- 2025-10-25T12:45:07Z : Uniformisation des symboles dans le flux SSE (`BTC/USDT`) et ajout d'un test async v√©rifiant l'√©v√©nement `tool_start` normalis√©.
- 2025-10-25T13:20:00Z : Documentation SSE align√©e sur la normalisation `BASE/QUOTE` et test unitaire couvrant la propagation des erreurs d'indicateur dans le pipeline streaming.
- 2025-10-25T13:48:35Z : Correction des avertissements Ruff D202 en supprimant les lignes vides apr√®s docstrings dans les tests streaming ; v√©rifications `ruff` et `pytest` effectu√©es.
